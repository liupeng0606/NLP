# CNN在NLP中的应用
## 1. CNN是什么
CNN在图像分类的领域取得了重大的突破，成为了当今计算机视觉系统的核心．CNN的做法是，在每一层（除去全连接层）使用ｎ个不同的卷积核，对图像做ｎ个特征提取，第一层通常可以检测到边缘信息，第二层通过边缘信息发现一些简单的形状，在更高的层，使用这些形状发现一些高级的特征，最后使用这些高级特征分类．<br><br>
简单的理解就是，从图像的像素中提取边缘，从边缘中发现形状和轮廓，再从轮廓中发现更复杂的对象．
## 2. CNN是如何利用到NLP领域的
>为什么需要CNN,CNN解决了那些问题,先引入一个问题．<br>
I hate the dog<br>
I love the dog<br>
传统的词袋模型，可以通过一个全连接的神经网络对句子进行情感分析，通过激活函数，可以让某些节点激活，（例如hate，good这样较强的特征词），对上述的两个句子可以很好的识别．但是这样存在一个问题，在一个句子中，词的顺序被忽略了，如　I do not hate the dog(表示喜欢)　和 I hate the dog and not let it follow me（表示不喜欢），词袋模型无法获取连续两个或多个词构成的关键特征词的含义．而卷积神经网络，利用卷积核，可以覆盖多个词，解决上述问题．



## 3. CNN应用到NLP需要解决哪些问题
1. 如何解决长度不一的问题
>这是一个必须要解决的问题，在NLP领域，通常采用的是＂单层CNN结构＂，这里的单层不是仅仅只有一层．而是只有一对卷积层和池化层，不同于图像的像素，NLP大多处理的是句子或者文档，需要把句子或者文档作为一个矩阵输入到NLP中，矩阵的每一行表示一个词，也即是每行是一个词向量，这些词向量，可以通过word2vec的方式得到，也可以通过ont-hot编码得到．假如每一个词的向量是３００维的，一个句子包含１０个词，那么输入矩阵就是１０＊３００，这个矩阵就可以抽象为CNN要处理的图，在图像处理中，卷积核会在图像中滑动，但是在ＮＬＰ中，卷积核需要上下滑动，也即是卷积核的宽度需要和输入矩阵的宽度一致才行，滑动窗口一般为２－５，CNN在NLP的应用过程如下图：
 ![image](https://github.com/liupeng0606/NLP/1.png)<br>
>上图展示了CNN在文本分类的使用，使用了2种过滤器（卷积核），每个过滤器有3种高度（区域大小），即有6种卷积结构（左起第2列），所以会产生6中卷积后的结果（左起第3列），经过最大池化层，每个卷积的结果将变为1个值（左起第4列），最终生成一个向量（左起第5列），这个向量的维度和卷积核的数量相同，这样也就解决了句子或文本长度不一的问题，最终经过分类器得到一个二分类结果（最后一列）。

